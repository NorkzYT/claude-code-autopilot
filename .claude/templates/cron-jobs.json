{
  "$schema": "https://openclaw.dev/schema/cron-jobs.json",
  "jobs": [
    {
      "name": "nightly-tests",
      "description": "Run full test suite and report failures",
      "schedule": "0 2 * * *",
      "timezone": "UTC",
      "enabled": true,
      "command": "exec npm test 2>&1 || exec python -m pytest 2>&1",
      "delivery": "announce",
      "on_failure": "alert",
      "timeout_seconds": 300
    },
    {
      "name": "dep-audit-weekly",
      "description": "Dependency security audit (npm audit + pip audit)",
      "schedule": "0 9 * * 1",
      "timezone": "UTC",
      "enabled": true,
      "command": "exec npm audit --audit-level=high 2>&1; exec pip audit 2>&1 || true",
      "delivery": "announce",
      "on_failure": "alert",
      "timeout_seconds": 120
    },
    {
      "name": "cost-summary-daily",
      "description": "Token usage and cost summary from tracking logs",
      "schedule": "0 18 * * *",
      "timezone": "UTC",
      "enabled": true,
      "command": "claude --print '/tools:cost-report'",
      "delivery": "announce",
      "on_failure": "log",
      "timeout_seconds": 60
    },
    {
      "name": "heartbeat",
      "description": "Health check: git status, tests, deps, disk usage",
      "schedule": "*/30 8-23 * * *",
      "timezone": "UTC",
      "enabled": false,
      "command": "exec bash -c 'echo \"=== GIT STATUS ===\"; git status --short; echo \"=== QUICK TEST ===\"; npm test 2>&1 | tail -5 || python -m pytest --tb=no -q 2>&1 | tail -5; echo \"=== DISK ===\"; df -h / | tail -1'",
      "delivery": "announce",
      "on_failure": "alert",
      "report_on_issues_only": true,
      "timeout_seconds": 180
    },
    {
      "name": "data-verification",
      "description": "Compare scraped data against live website data and fix discrepancies",
      "schedule": "0 3 * * *",
      "timezone": "UTC",
      "enabled": false,
      "command": "OPENCLAW_AUTONOMOUS=1 claude --print 'Use the autopilot subagent for this task: Run data verification pattern from AGENTS.md. Compare scraped vs live data, fix any scraping bugs, commit fixes on feature branch, report results.'",
      "delivery": "announce",
      "on_failure": "alert",
      "timeout_seconds": 1800,
      "env": {
        "OPENCLAW_AUTONOMOUS": "1"
      }
    },
    {
      "name": "api-discovery",
      "description": "Capture HAR files and document API patterns from target sites",
      "schedule": "0 4 * * 1",
      "timezone": "UTC",
      "enabled": false,
      "command": "OPENCLAW_AUTONOMOUS=1 claude --print 'Use the autopilot subagent for this task: Run API reverse engineering pattern from AGENTS.md. Capture HAR files, analyze endpoints, document findings in context.md.'",
      "delivery": "announce",
      "on_failure": "alert",
      "timeout_seconds": 1200,
      "env": {
        "OPENCLAW_AUTONOMOUS": "1"
      }
    },
    {
      "name": "repo-index-refresh",
      "description": "Weekly refresh of project metadata and deep codebase scan",
      "schedule": "0 3 * * 0",
      "timezone": "UTC",
      "enabled": false,
      "command": "bash .claude/bootstrap/analyze_repo.sh $WORKSPACE --deep",
      "delivery": "log",
      "on_failure": "log",
      "timeout_seconds": 300
    }
  ]
}
